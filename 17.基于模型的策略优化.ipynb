{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dda6dea",
   "metadata": {},
   "source": [
    "# 17. 基于模型的策略优化\n",
    "\n",
    "\n",
    "## 17.1 简介\n",
    "- 第 16 章介绍的 PETS 算法是基于模型的强化学习算法中的一种，它没有显式构建一个策略（即一个从状态到动作的映射函数）。回顾一下之前介绍过的 Dyna-Q 算法，它也是一种基于模型的强化学习算法。但是 Dyna-Q 算法中的模型只存储之前遇到的数据，只适用于表格型环境。而在连续型状态和动作的环境中，我们需要像 PETS 算法一样学习一个用神经网络表示的环境模型，此时若继续利用 Dyna 的思想，可以在任意状态和动作下用环境模型来生成一些虚拟数据，这些虚拟数据可以帮助进行策略的学习。如此，通过和模型进行交互产生额外的虚拟数据，对真实环境中样本的需求量就会减少，因此通常会比无模型的强化学习方法具有更高的采样效率。本章将介绍这样一种算法——MBPO 算法。\n",
    "\n",
    "## 17.2 MBPO 算法\n",
    "- **基于模型的策略优化** (model-based policy optimization，MBPO）算法是加州大学伯克利分校的研究员在 2019 年的 NeurIPS 会议中提出的。随即 MBPO 成为深度强化学习中最重要的基于模型的强化学习算法之一。\n",
    "\n",
    "- MBPO 算法基于以下两个关键的观察： (1) 随着环境模型的推演步数变长，模型累积的复合误差会快速增加，使得环境模型得出的结果变得很不可靠； (2) 必须要权衡推演步数增加后模型增加的误差带来的负面作用与步数增加后使得训练的策略更优的正面作用，二者的权衡决定了推演的步数。\n",
    "\n",
    "- MBPO 算法在这两个观察的基础之上，提出只使用模型来从之前访问过的真实状态开始进行较短步数的推演，而非从初始状态开始进行完整的推演。这就是 MBPO 中的分支推演（branched rollout）的概念，即在原来真实环境中采样的轨迹上面推演出新的“短分支”，如图 17-1 所示。这样做可以使模型的累积误差不至于过大，从而保证最后的采样效率和策略表现。\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./image/17-1.png\" style = \"width: 65%\">\n",
    "    <center>图 17-1 分支推演示意图</center>\n",
    "</div>\n",
    "\n",
    "- MBPO 与第 6 章讲解的经典的 Dyna-Q 算法十分类似。Dyna-Q 采用的无模型强化学习部分是 Q-learning，而 MBPO 采用的是 SAC。此外，MBPO 算法中环境模型的构建和 PETS 算法中一致，都使用模型集成的方式，并且其中每一个环境模型的输出都是一个高斯分布。接下来，我们来看一下 MBPO 的具体算法框架。MBPO 算法会把真实环境样本作为分支推演的起点，使用模型进行一定步数的推演，并用推演得到的模型数据用来训练模型。\n",
    "    - 初始化策略 $\\pi_{\\phi}$、环境模型参数 $p_{\\theta}$、真实环境数据集 $D_{env}$、模型数据集 $D_{model}$\n",
    "    - for 轮数 $n = 1 \\to T$ do:\n",
    "        - 通过环境数据来训练模型参数 $p_{\\theta}$\n",
    "        - for 时间步 $t = 1 \\to T$ do:\n",
    "            - 根据策略 $\\pi_{\\phi}$ 与环境交互，并将交互的轨迹添加到 $D_{env}$ 中\n",
    "            - for 模型推演次数 $e = 1 \\to E$ do\n",
    "                - 从 $D_{env}$ 中均匀随机采样一个状态 $s_t$\n",
    "                - 以 $s_t$ 为初始状态，在模型中使用策略 $\\pi_{\\phi}$ 进行 $k$ 步的推演，并将生成的轨迹添加到 $D_{model}$ 中\n",
    "            - end for\n",
    "            - for 梯度更新次数 $g = 1 \\to G$ do:\n",
    "                - 基于模型数据 $D_{model}$，使用 SAC 来更新策略参数 $\\pi_{\\theta}$\n",
    "            - end for\n",
    "        - end for\n",
    "    - end for\n",
    "\n",
    "- 分支推演长度 $k$ 是平衡样本效率和策略性能的重要超参数。接下来我们看看 MBPO 的代码，本章最后会给出关于 MBPO 的理论推导，可以指导参数 $k$ 的选取。\n",
    "\n",
    "## 17.3 MBPO 代码实践 \n",
    "- 首先，我们先导入一些必要的包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07d33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ac1a4",
   "metadata": {},
   "source": [
    "- MBPO 算法使用 SAC 算法来训练策略。和 SAC 算法相比，MBPO 多用了一些模型推演得到的数据来训练策略。要想了解 SAC 方法的详细过程，读者可以阅读第 14 章对应的内容。我们将 SAC 代码直接复制到此处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58a94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, action_bound):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc_mu = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.fc_std = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.action_bound = action_bound\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        std = F.softplus(self.fc_std(x))\n",
    "        dist = Normal(mu, std)\n",
    "        normal_sample = dist.rsample()  # rsample()是重参数化采样函数\n",
    "        log_prob = dist.log_prob(normal_sample)\n",
    "        action = torch.tanh(normal_sample)  # 计算tanh_normal分布的对数概率密度\n",
    "        log_prob = log_prob - torch.log(1 - torch.tanh(action).pow(2) + 1e-7)\n",
    "        action = action * self.action_bound\n",
    "        return action, log_prob\n",
    "\n",
    "\n",
    "class QValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(QValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim + action_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        cat = torch.cat([x, a], dim=1)  # 拼接状态和动作\n",
    "        x = F.relu(self.fc1(cat))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "\n",
    "class SAC:\n",
    "    ''' 处理连续动作的SAC算法 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, action_bound,\n",
    "                 actor_lr, critic_lr, alpha_lr, target_entropy, tau, gamma):\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim,\n",
    "                               action_bound).to(device)  # 策略网络\n",
    "        # 第一个Q网络\n",
    "        self.critic_1 = QValueNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        # 第二个Q网络\n",
    "        self.critic_2 = QValueNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.target_critic_1 = QValueNet(state_dim, hidden_dim,\n",
    "                                         action_dim).to(device)  # 第一个目标Q网络\n",
    "        self.target_critic_2 = QValueNet(state_dim, hidden_dim,\n",
    "                                         action_dim).to(device)  # 第二个目标Q网络\n",
    "        # 令目标Q网络的初始参数和Q网络一样\n",
    "        self.target_critic_1.load_state_dict(self.critic_1.state_dict())\n",
    "        self.target_critic_2.load_state_dict(self.critic_2.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                lr=actor_lr)\n",
    "        self.critic_1_optimizer = torch.optim.Adam(self.critic_1.parameters(),\n",
    "                                                   lr=critic_lr)\n",
    "        self.critic_2_optimizer = torch.optim.Adam(self.critic_2.parameters(),\n",
    "                                                   lr=critic_lr)\n",
    "        # 使用alpha的log值,可以使训练结果比较稳定\n",
    "        self.log_alpha = torch.tensor(np.log(0.01), dtype=torch.float)\n",
    "        self.log_alpha.requires_grad = True  # 可以对alpha求梯度\n",
    "        self.log_alpha_optimizer = torch.optim.Adam([self.log_alpha],\n",
    "                                                    lr=alpha_lr)\n",
    "        self.target_entropy = target_entropy  # 目标熵的大小\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(device)\n",
    "        action = self.actor(state)[0]\n",
    "        return [action.item()]\n",
    "\n",
    "    def calc_target(self, rewards, next_states, dones):  # 计算目标Q值\n",
    "        next_actions, log_prob = self.actor(next_states)\n",
    "        entropy = -log_prob\n",
    "        q1_value = self.target_critic_1(next_states, next_actions)\n",
    "        q2_value = self.target_critic_2(next_states, next_actions)\n",
    "        next_value = torch.min(q1_value,\n",
    "                               q2_value) + self.log_alpha.exp() * entropy\n",
    "        td_target = rewards + self.gamma * next_value * (1 - dones)\n",
    "        return td_target\n",
    "\n",
    "    def soft_update(self, net, target_net):\n",
    "        for param_target, param in zip(target_net.parameters(),\n",
    "                                       net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - self.tau) +\n",
    "                                    param.data * self.tau)\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(transition_dict['actions'],\n",
    "                               dtype=torch.float).view(-1, 1).to(device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(device)\n",
    "        rewards = (rewards + 8.0) / 8.0  # 对倒立摆环境的奖励进行重塑\n",
    "\n",
    "        # 更新两个Q网络\n",
    "        td_target = self.calc_target(rewards, next_states, dones)\n",
    "        critic_1_loss = torch.mean(\n",
    "            F.mse_loss(self.critic_1(states, actions), td_target.detach()))\n",
    "        critic_2_loss = torch.mean(\n",
    "            F.mse_loss(self.critic_2(states, actions), td_target.detach()))\n",
    "        self.critic_1_optimizer.zero_grad()\n",
    "        critic_1_loss.backward()\n",
    "        self.critic_1_optimizer.step()\n",
    "        self.critic_2_optimizer.zero_grad()\n",
    "        critic_2_loss.backward()\n",
    "        self.critic_2_optimizer.step()\n",
    "\n",
    "        # 更新策略网络\n",
    "        new_actions, log_prob = self.actor(states)\n",
    "        entropy = -log_prob\n",
    "        q1_value = self.critic_1(states, new_actions)\n",
    "        q2_value = self.critic_2(states, new_actions)\n",
    "        actor_loss = torch.mean(-self.log_alpha.exp() * entropy -\n",
    "                                torch.min(q1_value, q2_value))\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # 更新alpha值\n",
    "        alpha_loss = torch.mean(\n",
    "            (entropy - self.target_entropy).detach() * self.log_alpha.exp())\n",
    "        self.log_alpha_optimizer.zero_grad()\n",
    "        alpha_loss.backward()\n",
    "        self.log_alpha_optimizer.step()\n",
    "\n",
    "        self.soft_update(self.critic_1, self.target_critic_1)\n",
    "        self.soft_update(self.critic_2, self.target_critic_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fbf308",
   "metadata": {},
   "source": [
    "- 接下来定义环境模型，注意这里的环境模型和 PETS 算法中的环境模型是一样的，由多个高斯分布策略的集成来构建。我们也沿用 PETS 算法中的模型构建代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722d7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    ''' Swish激活函数 '''\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    ''' 初始化模型权重 '''\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)\n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):\n",
    "                break\n",
    "            t = torch.where(\n",
    "                cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),\n",
    "                                      mean=mean,\n",
    "                                      std=std), t)\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    ''' 集成之后的全连接层 '''\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(\n",
    "            torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159813e",
   "metadata": {},
   "source": [
    "- 接着，我们就可以定义集成模型了，其中就会用到刚刚定义的全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ad2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    ''' 环境模型集成 '''\n",
    "    def __init__(self,\n",
    "                 state_dim,\n",
    "                 action_dim,\n",
    "                 model_alpha,\n",
    "                 ensemble_size=5,\n",
    "                 learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        # 输出包括均值和方差,因此是状态与奖励维度之和的两倍\n",
    "        self._output_dim = (state_dim + 1) * 2\n",
    "        self._model_alpha = model_alpha  # 模型损失函数中加权时的权重\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),\n",
    "                                        requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),\n",
    "                                        requires_grad=False)\n",
    "\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size,\n",
    "                              Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size,\n",
    "                              nn.Identity())\n",
    "        self.apply(init_weights)  # 初始化环境模型中的参数\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(\n",
    "            self.layer1(x)))))\n",
    "        mean = ret[:, :, :self._output_dim // 2]\n",
    "        # 在PETS算法中,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(\n",
    "            self._max_logvar - ret[:, :, self._output_dim // 2:])\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) *\n",
    "                                             inverse_var,\n",
    "                                             dim=-1),\n",
    "                                  dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss += self._model_alpha * torch.sum(\n",
    "            self._max_logvar) - self._model_alpha * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "class EnsembleDynamicsModel:\n",
    "    ''' 环境模型集成,加入精细化的训练 '''\n",
    "    def __init__(self, state_dim, action_dim, model_alpha=0.01, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim,\n",
    "                                   action_dim,\n",
    "                                   model_alpha,\n",
    "                                   ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0\n",
    "\n",
    "    def train(self,\n",
    "              inputs,\n",
    "              labels,\n",
    "              batch_size=64,\n",
    "              holdout_ratio=0.1,\n",
    "              max_iter=20):\n",
    "        # 设置训练集与验证集\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]\n",
    "        holdout_inputs, holdout_labels = inputs[:\n",
    "                                                num_holdout], labels[:\n",
    "                                                                     num_holdout]\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat(\n",
    "            [self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat(\n",
    "            [self._num_network, 1, 1])\n",
    "\n",
    "        # 保留最好的结果\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "        for epoch in itertools.count():\n",
    "            # 定义每一个网络的训练数据\n",
    "            train_index = np.vstack([\n",
    "                np.random.permutation(train_inputs.shape[0])\n",
    "                for _ in range(self._num_network)\n",
    "            ])\n",
    "            # 所有真实数据都用来训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos +\n",
    "                                          batch_size]\n",
    "                train_input = torch.from_numpy(\n",
    "                    train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(\n",
    "                    train_labels[batch_index]).float().to(device)\n",
    "\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train(loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean,\n",
    "                                                    logvar,\n",
    "                                                    holdout_labels,\n",
    "                                                    use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):\n",
    "        inputs = np.tile(inputs, (self._num_network, 1, 1))\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float).to(device)\n",
    "        mean, var = self.model(inputs, return_log_var=False)\n",
    "        return mean.detach().cpu().numpy(), var.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)\n",
    "        ensemble_model_means[:, :, 1:] += obs\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(\n",
    "            size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        models_to_use = np.random.choice(\n",
    "            [i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        rewards, next_obs = samples[:, :1][0][0], samples[:, 1:][0]\n",
    "        return rewards, next_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b6491",
   "metadata": {},
   "source": [
    "- 最后，我们来实现 MBPO 算法的具体流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fee37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBPO:\n",
    "    def __init__(self, env, agent, fake_env, env_pool, model_pool,\n",
    "                 rollout_length, rollout_batch_size, real_ratio, num_episode):\n",
    "\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.fake_env = fake_env\n",
    "        self.env_pool = env_pool\n",
    "        self.model_pool = model_pool\n",
    "        self.rollout_length = rollout_length\n",
    "        self.rollout_batch_size = rollout_batch_size\n",
    "        self.real_ratio = real_ratio\n",
    "        self.num_episode = num_episode\n",
    "\n",
    "    def rollout_model(self):\n",
    "        observations, _, _, _, _ = self.env_pool.sample(\n",
    "            self.rollout_batch_size)\n",
    "        for obs in observations:\n",
    "            for i in range(self.rollout_length):\n",
    "                action = self.agent.take_action(obs)\n",
    "                reward, next_obs = self.fake_env.step(obs, action)\n",
    "                self.model_pool.add(obs, action, reward, next_obs, False)\n",
    "                obs = next_obs\n",
    "\n",
    "    def update_agent(self, policy_train_batch_size=64):\n",
    "        env_batch_size = int(policy_train_batch_size * self.real_ratio)\n",
    "        model_batch_size = policy_train_batch_size - env_batch_size\n",
    "        for epoch in range(10):\n",
    "            env_obs, env_action, env_reward, env_next_obs, env_done = self.env_pool.sample(\n",
    "                env_batch_size)\n",
    "            if self.model_pool.size() > 0:\n",
    "                model_obs, model_action, model_reward, model_next_obs, model_done = self.model_pool.sample(\n",
    "                    model_batch_size)\n",
    "                obs = np.concatenate((env_obs, model_obs), axis=0)\n",
    "                action = np.concatenate((env_action, model_action), axis=0)\n",
    "                next_obs = np.concatenate((env_next_obs, model_next_obs),\n",
    "                                          axis=0)\n",
    "                reward = np.concatenate((env_reward, model_reward), axis=0)\n",
    "                done = np.concatenate((env_done, model_done), axis=0)\n",
    "            else:\n",
    "                obs, action, next_obs, reward, done = env_obs, env_action, env_next_obs, env_reward, env_done\n",
    "            transition_dict = {\n",
    "                'states': obs,\n",
    "                'actions': action,\n",
    "                'next_states': next_obs,\n",
    "                'rewards': reward,\n",
    "                'dones': done\n",
    "            }\n",
    "            self.agent.update(transition_dict)\n",
    "\n",
    "    def train_model(self):\n",
    "        obs, action, reward, next_obs, done = self.env_pool.return_all_samples(\n",
    "        )\n",
    "        inputs = np.concatenate((obs, action), axis=-1)\n",
    "        reward = np.array(reward)\n",
    "        labels = np.concatenate(\n",
    "            (np.reshape(reward, (reward.shape[0], -1)), next_obs - obs),\n",
    "            axis=-1)\n",
    "        self.fake_env.model.train(inputs, labels)\n",
    "\n",
    "    def explore(self):\n",
    "        obs, done, episode_return = self.env.reset(), False, 0\n",
    "        while not done:\n",
    "            action = self.agent.take_action(obs)\n",
    "            next_obs, reward, done, _ = self.env.step(action)\n",
    "            self.env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 随机探索采取数据\n",
    "        print('episode: 1, return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episode - 1):\n",
    "            obs, done, episode_return = self.env.reset(), False, 0\n",
    "            step = 0\n",
    "            while not done:\n",
    "                if step % 50 == 0:\n",
    "                    self.train_model()\n",
    "                    self.rollout_model()\n",
    "                action = self.agent.take_action(obs)\n",
    "                next_obs, reward, done, _ = self.env.step(action)\n",
    "                self.env_pool.add(obs, action, reward, next_obs, done)\n",
    "                obs = next_obs\n",
    "                episode_return += reward\n",
    "\n",
    "                self.update_agent()\n",
    "                step += 1\n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            return self.return_all_samples()\n",
    "        else:\n",
    "            transitions = random.sample(self.buffer, batch_size)\n",
    "            state, action, reward, next_state, done = zip(*transitions)\n",
    "            return np.array(state), action, reward, np.array(next_state), done\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036635f",
   "metadata": {},
   "source": [
    "- 对于不同的环境，我们需要设置不同的参数。这里以 OpenAI Gym 中的 Pendulum-v1 环境为例，给出一组效果较为不错的参数。读者可以试着自己调节参数，观察调节后的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cd9a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxl/anaconda3/envs/d2l/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/wxl/anaconda3/envs/d2l/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/tmp/ipykernel_685578/438640068.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  state = torch.tensor([state], dtype=torch.float).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, return: -1566\n",
      "episode: 2, return: -1670\n",
      "episode: 3, return: -1418\n",
      "episode: 4, return: -1604\n",
      "episode: 5, return: -1603\n",
      "episode: 6, return: -1670\n",
      "episode: 7, return: -1668\n",
      "episode: 8, return: -1664\n",
      "episode: 9, return: -1599\n",
      "episode: 10, return: -1571\n",
      "episode: 11, return: -1588\n",
      "episode: 12, return: -1346\n",
      "episode: 13, return: -1680\n",
      "episode: 14, return: -1077\n",
      "episode: 15, return: -1166\n",
      "episode: 16, return: -1139\n",
      "episode: 17, return: -1674\n",
      "episode: 18, return: -1054\n",
      "episode: 19, return: -1607\n",
      "episode: 20, return: -1679\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_ratio = 0.5\n",
    "env_name = 'Pendulum-v1'\n",
    "env = gym.make(env_name)\n",
    "num_episodes = 20\n",
    "actor_lr = 5e-4\n",
    "critic_lr = 5e-3\n",
    "alpha_lr = 1e-3\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "tau = 0.005  # 软更新参数\n",
    "buffer_size = 10000\n",
    "target_entropy = -1\n",
    "model_alpha = 0.01  # 模型损失函数中的加权权重\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high[0]  # 动作最大值\n",
    "\n",
    "rollout_batch_size = 1000\n",
    "rollout_length = 1  # 推演长度k,推荐更多尝试\n",
    "model_pool_size = rollout_batch_size * rollout_length\n",
    "\n",
    "agent = SAC(state_dim, hidden_dim, action_dim, action_bound, actor_lr,\n",
    "            critic_lr, alpha_lr, target_entropy, tau, gamma)\n",
    "model = EnsembleDynamicsModel(state_dim, action_dim, model_alpha)\n",
    "fake_env = FakeEnv(model)\n",
    "env_pool = ReplayBuffer(buffer_size)\n",
    "model_pool = ReplayBuffer(model_pool_size)\n",
    "mbpo = MBPO(env, agent, fake_env, env_pool, model_pool, rollout_length,\n",
    "            rollout_batch_size, real_ratio, num_episodes)\n",
    "\n",
    "return_list = mbpo.train()\n",
    "\n",
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('MBPO on {}'.format(env_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cbb53",
   "metadata": {},
   "source": [
    "- 可以看到，相比无模型的强化学习算法，基于模型的方法 MBPO 在样本效率上要高很多。虽然这里的效果可能不如 16.3 节提到的 PETS 算法优秀，但是在许多更加复杂的环境中（如 Hopper 和 HalfCheetah），MBPO 的表现远远好于 PETS 算法。\n",
    "\n",
    "## 17.4 小结\n",
    "- MBPO 算法是一种前沿的基于模型的强化学习算法，它提出了一个重要的概念——分支推演。在各种复杂的环境中，作者验证了 MBPO 的效果超过了之前基于模型的方法。MBPO 对于基于模型的强化学习的发展起着重要的作用，不少之后的工作都是在此基础上进行的。\n",
    "\n",
    "- 除了算法的有效性，MBPO 的重要贡献还包括它给出了关于分支推演步数与模型误差、策略偏移程度之间的定量关系，进而阐明了什么时候我们可以相信并使用环境模型，什么样的环境导出的最优分支推演步数为 0，进而建议不使用环境模型。相应的理论分析在 17.5 节给出。\n",
    "\n",
    "## 17.5 拓展阅读：MBPO 理论分析\n",
    "\n",
    "### 17.5.1 性能提升的单调性保障\n",
    "- 基于模型的方法往往是在环境模型中提升策略的性能，但这并不能保证在真实环境中策略性能也有所提升。因此，我们希望模型环境和真实环境中的结果的差距有一定的限制，具体可形式化为：\n",
    "\n",
    "$$\n",
    "\\eta[\\pi]\\geq\\hat{\\eta}[\\pi]-C,\n",
    "$$\n",
    "\n",
    "- 其中，$\\eta[\\pi]$ 表示策略在真实环境中的期望回报，而 $\\hat{\\eta}[\\pi]$ 表示策略在环境模型中的期望回报。这一公式保证了在模型环境中提高策略性能超过 $C$ 时，就可以在真实环境中取得策略性能的提升。在 MBPO 中，根据泛化误差和分布偏移估计出这样一个下界：\n",
    "\n",
    "$$\n",
    "\\eta[\\pi]\\geq\\hat{\\eta}[\\pi]-\\left[\\frac{2\\gamma r_{\\max}(\\epsilon_{m}+2\\epsilon_{\\pi})}{(1-\\gamma)^{2}}+\\frac{4r_{\\max}\\epsilon_{\\pi}}{(1-\\gamma)}\\right],\n",
    "$$\n",
    "\n",
    "- 其中，$\\epsilon_m=\\max_t\\mathbb{E}_{s\\sim\\pi_{D,t}}[D_{TV}(p(s^{\\prime},r|s,a)\\|p_\\theta(s^{\\prime},r|s,a))]$ 刻画了当前策略 $\\pi$ 与数据收集策略 $\\pi_D$ 之间的**策略转移**（policy shift）。\n",
    "\n",
    "### 17.5.2 模型推演长度\n",
    "- 在上面的公式里，如果模型泛化误差很大，就可能不存在一个使得推演误 $C$ 最小的正数推演步数 $k$，进而无法使用模型。因此作者提出了**分支推演**（branched rollout）的办法，即从之前访问过的状态开始进行有限制的推演，从而保证模型工作时的泛化误差不要太大。\n",
    "\n",
    "- 如果我们使用当前策略 $\\pi_t$ 而非本轮之前的数据收集策略 $\\pi_D$，$t$ 来估计模型误差（记为：$\\epsilon^{\\prime}_{m}$），那么有：\n",
    "\n",
    "$$\n",
    "\\epsilon_m^{\\prime}=\\max_t\\mathbb{E}_{s\\sim\\pi_t}[D_{TV}(p(s^{\\prime},r|s,a)\\|p_\\theta(s^{\\prime},r|s,a))]\n",
    "$$\n",
    "\n",
    "- 并且对其进行线性近似：\n",
    "\n",
    "$$\n",
    "\\epsilon_m^{\\prime}\\approx\\epsilon_m+\\epsilon_\\pi\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}\n",
    "$$\n",
    "\n",
    "- 结合上 $k$ 步分支推演，我们就可以得到一个新的策略期望回报界：\n",
    "\n",
    "$$\n",
    "\\eta[\\pi]\\geq\\eta^\\mathrm{branch}[\\pi]-2r_\\mathrm{max}\\left[\\frac{\\gamma^{k+1}\\epsilon_\\pi}{(1-\\gamma)^2}+\\frac{\\gamma^k\\epsilon_\\pi}{(1-\\gamma)}+\\frac{k}{1-\\gamma}\\epsilon_{m^{\\prime}}\\right]\n",
    "$$\n",
    "\n",
    "- 其中，$\\eta^{\\mathrm{branch}}[\\pi]$ 表示使用分支推演的方法得到的策略期望回报。通过以上公式，我们就可以得到理论最优的推演步长，即：\n",
    "\n",
    "$$\n",
    "k^*=\\operatorname{argmin}_k\\left[\\frac{\\gamma^{k+1}\\epsilon_\\pi}{(1-\\gamma)^2}+\\frac{\\gamma^k\\epsilon_\\pi}{(1-\\gamma)}+\\frac{k}{1-\\gamma}\\epsilon_{m^{\\prime}}\\right]\n",
    "$$\n",
    "\n",
    "- 在上式中可以看到，对于 $\\gamma \\in (0,1)$，当推演步数变大时，$\\frac{\\gamma^{k+1}\\epsilon_\\pi}{(1-\\gamma)^2}+\\frac{\\gamma^k\\epsilon_\\pi}{(1-\\gamma)}$ 变小，而 $\\frac{k}{1-\\gamma}\\epsilon_{m^{\\prime}}$ 变大。更进一步，如果 $\\epsilon^{\\prime}_{m}$ 足够小的话，由 $\\epsilon_m^{\\prime}\\approx\\epsilon_m+\\epsilon_\\pi\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$ 的关系可知，如果 $\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$ 足够小，那么最优推演步长 $k$ 就是为正，时分支推演（或者说使用基于模型的方法）就是一个有效的方法。\n",
    "\n",
    "- MBPO 论文中展示了在主流的机器人运动环境 Mojoco 的典型场景中，$\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$ 的数量级非常小，大约都在 $[10^{-4}, 10^{-2}]$ 区间，而且可以看出它随着训练数据的增多的而不断下降，说明模型的泛化能力逐渐增强，而我们对于推演步长为正数的假设也是合理的。但要知道，并不是所有的强化学习环境都可以有如此小的 $\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$。例如在高随机性的离散状态环境中，往往环境模型的拟合精度较低，以至于 $\\frac{\\mathrm{d}\\epsilon_m^{\\prime}}{\\mathrm{d}\\epsilon_\\pi}$ 较大，此时使用基于分支推演的方法效果有限。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
